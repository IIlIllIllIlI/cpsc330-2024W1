
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Lecture 9: Class demo &#8212; CPSC 330 Applied Machine Learning 2024W1</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/extra.css?v=6df0ab2b" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../README.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/UBC-CS-logo.png" class="logo__image only-light" alt="CPSC 330 Applied Machine Learning 2024W1 - Home"/>
    <script>document.write(`<img src="../../../_static/UBC-CS-logo.png" class="logo__image only-dark" alt="CPSC 330 Applied Machine Learning 2024W1 - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../README.html">
                    UBC CPSC 330: Applied Machine Learning (2024W1)
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Things you should know</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../syllabus.html">Syllabus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../docs/README.html">CPSC 330 Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../learning-objectives.html">Course Learning Objectives</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../notes/01_intro.html">Lecture 1: Course Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/02_terminology-decision-trees.html">Lecture 2: Terminology, Baselines, Decision Trees</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/03_ml-fundamentals.html">Lecture 3: Machine Learning Fundamentals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/04_kNNs-SVM-RBF.html">Lecture 4: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours and SVM RBFs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/05_preprocessing-pipelines.html">Lecture 5: Preprocessing and <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> pipelines</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/06_column-transformer-text-feats.html">Lecture 6: <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code> and Text Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/07_linear-models.html">Lecture 7: Linear Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/08_hyperparameter-optimization.html">Lecture 8: Hyperparameter Optimization and Optimization Bias</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/09_classification-metrics.html">Lecture 9: Classification metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../notes/10_regression-metrics.html">Lecture 10: Regression metrics</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Section slides</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../101-Giulia-lectures/README.html">Section 101</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/01_intro.html">Lecture 1: Course Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/02_terminology-decision-trees.html">Lecture 2: Terminology, Baselines, Decision Trees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/03_ml-fundamentals.html">Lecture 3: Machine Learning Fundamentals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/04_kNNs-SVM-RBF.html">Lecture 4: <span class="math notranslate nohighlight">\(k\)</span>-Nearest Neighbours and SVM RBFs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/05_preprocessing-pipelines.html">Lecture 5: Preprocessing and <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/06_column-transformer-text-feats.html">Lecture 6: <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> <code class="docutils literal notranslate"><span class="pre">ColumnTransformer</span></code> and Text Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/07_linear-models.html">Lecture 7: Linear Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../101-Giulia-lectures/08_hyperparameter-optimization.html">Lecture 8: Hyperparameter Optimization and Optimization Bias</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../README.html">Section 102</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-01.html">Lecture 1</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-02.html">Lecture 2</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-03.html">Lecture 3</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-04.html">Lecture 4</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-05.html">Lecture 5</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-06.html">Lecture 6</a></li>
<li class="toctree-l2"><a class="reference external" href="https://kvarada.github.io/cpsc330-slides/lecture-07.html">Lecture 7</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../103-Firas-lectures/README.html">Section 103</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-01-intro">Lecture 1</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-02-terminology-decision-trees">Lecture 2</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-03-ml-fundamentals">Lecture 3</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-04-kNNs-SVM-RBF">Lecture 4</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-05-preprocessing-pipelines">Lecture 5</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-06">Lecture 6</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-07">Lecture 7</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-08">Lecture 8</a></li>
<li class="toctree-l2"><a class="reference external" href="https://firasm.github.io/cpsc330-slides/slides-09">Lecture 9</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Attribution</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../LICENSE.html">LICENSE</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/UBC-CS/cpsc330-2024W1" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/lectures/102-Varada-lectures/class_demos/demo_09-classification-metrics.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Lecture 9: Class demo</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-workflow">Machine learning workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics-for-binary-classification-motivation">Evaluation metrics for binary classification: Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-for-demonstration">Dataset for demonstration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eda">EDA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline">Baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#observations">Observations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thresholding">Thresholding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix">Confusion matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-types-of-errors-would-be-most-critical-for-the-bank-to-address">Which types of errors would be most critical for the bank to address?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-positive-and-negative">What is “positive” and “negative”?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix-with-cross-validation">Confusion matrix with cross-validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-f1-score">Precision, recall, f1 score</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-and-recall-toy-example">Precision and recall: toy example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recall">Recall</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score">F1-score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-report">Classification report</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interim-summary">Interim summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evalution-metrics-overview">Evalution metrics overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-with-different-metrics">Cross validation with different metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-curve">Precision-recall curve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#operating-point">Operating point</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-tradeoff">Precision/Recall tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decreasing-the-threshold">Decreasing the threshold</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#increasing-the-threshold">Increasing the threshold</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Precision-recall curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ap-score">AP score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ap-vs-f1-score">AP vs. F1-score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-few-comments-on-pr-curve">A few comments on PR curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-some-more-details">(Optional) Some more details</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pr-curves-for-logistic-regression-and-svc">PR curves for logistic regression and SVC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression">Which model is doing better in this scenario: SVC or Logistic Regression?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) curve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#area-under-the-curve-auc">Area under the curve (AUC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-look-at-all-the-scores-at-once">Let’s look at all the scores at once</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-class-imbalance-video">Dealing with class imbalance [video]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-imbalance-in-training-sets">Class imbalance in training sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#addressing-class-imbalance">Addressing class imbalance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-type-of-error-is-more-important">Which type of error is more important?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-imbalance">Handling imbalance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#changing-the-training-procedure">Changing the training procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-class-weight-parameter-of-sklearn-logisticregression">Example: <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">sklearn</span> <span class="pre">LogisticRegression</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-weight-balanced"><code class="docutils literal notranslate"><span class="pre">class_weight="balanced"</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-we-doing-better-with-class-weight-balanced">Are we doing better with <code class="docutils literal notranslate"><span class="pre">class_weight="balanced"</span></code>?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stratified-splits">Stratified Splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-stratifying-a-good-idea">Is stratifying a good idea?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-changing-the-data">(Optional) Changing the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#undersampling">Undersampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oversampling">Oversampling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smote-synthetic-minority-over-sampling-technique">SMOTE: Synthetic Minority Over-sampling Technique</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smote-idea">SMOTE idea</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-smote">Using SMOTE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-fairness-activity-5-mins">ML fairness activity (~5 mins)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#questions-for-group-discussion">❓❓ Questions for group discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-we-learn-today">What did we learn today?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-papers-and-resources">Relevant papers and resources</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="lecture-9-class-demo">
<h1>Lecture 9: Class demo<a class="headerlink" href="#lecture-9-class-demo" title="Link to this heading">#</a></h1>
<section id="imports">
<h2>Imports<a class="headerlink" href="#imports" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="s2">&quot;code&quot;</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">IPython</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">plotting_functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">cross_validate</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span><span class="p">,</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_colwidth&quot;</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">DATA_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="p">(</span><span class="s2">&quot;..&quot;</span><span class="p">),</span> <span class="s2">&quot;data/&quot;</span><span class="p">)</span>

<span class="c1"># Ignore future deprecation warnings from sklearn (using `os` instead of `warnings` also works in subprocesses)</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;PYTHONWARNINGS&#39;</span><span class="p">]</span><span class="o">=</span><span class="s1">&#39;ignore::FutureWarning&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Changing global matplotlib settings for confusion matrix.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;xtick.labelsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;ytick.labelsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="machine-learning-workflow">
<h2>Machine learning workflow<a class="headerlink" href="#machine-learning-workflow" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Here is a typical workflow of a supervised machine learning systems.</p></li>
<li><p>So far, we have talked about data splitting, preprocessing, some EDA, model selection with hyperparameter optimization, and interpretation in the context of linear models.</p></li>
<li><p>In the next few lectures, we will talk about evaluation metrics and model selection in terms of evaluation metrics, feature engineering, feature selection, and model transparency and interpretation.</p></li>
</ul>
<p><img alt="" src="../../../_images/ml-workflow.png" /></p>
<p><br><br><br><br></p>
</section>
<section id="evaluation-metrics-for-binary-classification-motivation">
<h2>Evaluation metrics for binary classification: Motivation<a class="headerlink" href="#evaluation-metrics-for-binary-classification-motivation" title="Link to this heading">#</a></h2>
<section id="dataset-for-demonstration">
<h3>Dataset for demonstration<a class="headerlink" href="#dataset-for-demonstration" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Let’s classify fraudulent and non-fraudulent transactions using Kaggle’s <a class="reference external" href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit Card Fraud Detection</a> data set.</p>
<ul>
<li><p>Note, that the credit card fraud detection data set is very large (150mb!) so we’ve stored it using <a class="reference external" href="https://josh-ops.com/posts/add-files-to-git-lfs/">GitLFS</a> in a personal repo. You should download the data locally to follow-along, and be sure not to commit large data files to your repository!</p></li>
</ul>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This dataset will be loaded using a URL instead of a CSV file</span>
<span class="n">DATA_URL</span> <span class="o">=</span> <span class="s2">&quot;https://github.com/firasm/bits/raw/refs/heads/master/creditcard.csv&quot;</span>

<span class="n">cc_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_URL</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;latin-1&quot;</span><span class="p">)</span>
<span class="c1"># Sorting columns so it is easier to read</span>
<span class="n">cc_df</span> <span class="o">=</span> <span class="n">cc_df</span><span class="p">[[</span><span class="s1">&#39;Class&#39;</span><span class="p">,</span> <span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="s1">&#39;Amount&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cc_df</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="n">cc_df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;V&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">to_list</span><span class="p">()]</span>

<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cc_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">111</span><span class="p">)</span>

<span class="n">train_df</span>

<span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cc_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">111</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Good size dataset</p></li>
<li><p>For confidentially reasons, it only provides transformed features with PCA, which is a popular dimensionality reduction technique.</p></li>
</ul>
</section>
<section id="eda">
<h3>EDA<a class="headerlink" href="#eda" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">(</span><span class="n">include</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We do not have categorical features. All features are numeric.</p></li>
<li><p>We have to be careful about the <code class="docutils literal notranslate"><span class="pre">Time</span></code> and <code class="docutils literal notranslate"><span class="pre">Amount</span></code> features.</p></li>
<li><p>We could scale <code class="docutils literal notranslate"><span class="pre">Amount</span></code>.</p></li>
<li><p>Do we want to scale time?</p>
<ul>
<li><p>In this lecture, we’ll just drop the Time feature.</p></li>
<li><p>We’ll learn about time series briefly later in the course.</p></li>
</ul>
</li>
</ul>
<p>Let’s separate <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> for train and test splits.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]),</span> <span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
<span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Time&quot;</span><span class="p">]),</span> <span class="n">test_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>It’s easier to demonstrate evaluation metrics using an explicit validation set instead of using cross-validation.</p></li>
<li><p>So let’s create a validation set.</p></li>
<li><p>Our data is large enough so it shouldn’t be a problem.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="baseline">
<h3>Baseline<a class="headerlink" href="#baseline" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">()</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">dummy</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="observations">
<h3>Observations<a class="headerlink" href="#observations" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> is getting 0.998 cross-validation accuracy!!</p></li>
<li><p>Should we be happy with this accuracy and deploy this <code class="docutils literal notranslate"><span class="pre">DummyClassifier</span></code> model for fraud detection?</p></li>
</ul>
<p>What’s the class distribution?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We have class imbalance.</p></li>
<li><p>We have MANY non-fraud transactions and only a handful of fraud transactions.</p></li>
<li><p>So in the training set, <code class="docutils literal notranslate"><span class="pre">most_frequent</span></code> strategy is labeling 199,025 (99.83%) instances correctly and only 339 (0.17%) instances incorrectly.</p></li>
<li><p>Is this what we want?</p></li>
<li><p>The “fraud” class is the important class that we want to spot.</p></li>
</ul>
<p>Let’s scale the features and try <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We are getting a slightly better score with logistic regression.</p></li>
<li><p>What score should be considered an acceptable score here?</p></li>
<li><p>Are we actually spotting any “fraud” transactions?</p></li>
</ul>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">.score</span></code> by default returns accuracy which is
$<span class="math notranslate nohighlight">\(\frac{\text{correct predictions}}{\text{total examples}}\)</span>$</p></li>
<li><p>Is accuracy a good metric here?</p></li>
<li><p>Is there anything more informative than accuracy that we can use here?</p></li>
</ul>
<p>Let’s dig a little deeper.</p>
<p><br><br><br><br></p>
</section>
</section>
<section id="thresholding">
<h2>Thresholding<a class="headerlink" href="#thresholding" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>We have a logistic regression model for fraud detection that predicts a value between 0 and 1, representing the probability that a given email is spam.</p></li>
<li><p>We use thresholding to get the binary prediction.</p></li>
<li><p>A typical threshold is 0.5.</p>
<ul>
<li><p>A prediction of 0.90 <span class="math notranslate nohighlight">\(\rightarrow\)</span> a high likelihood that the transaction is fraudulent and we predict <strong>fraud</strong></p></li>
<li><p>A prediction of 0.20 <span class="math notranslate nohighlight">\(\rightarrow\)</span> a low likelihood that the transaction is non-fraudulent and we predict <strong>Non fraud</strong></p></li>
</ul>
</li>
<li><p><strong>What happens if the predicted score is equal to the chosen threshold?</strong></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>

<span class="c1"># Create a link to the page</span>
<span class="n">link</span> <span class="o">=</span> <span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;a href=&#39;https://developers.google.com/machine-learning/crash-course/classification/thresholding&#39; target=&#39;_blank&#39;&gt;Visit the Classification Thresholding Interactive Page&lt;/a&gt;&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="confusion-matrix">
<h2>Confusion matrix<a class="headerlink" href="#confusion-matrix" title="Link to this heading">#</a></h2>
<p>One way to get a better understanding of the errors is by looking at</p>
<ul class="simple">
<li><p>false positives (type I errors), where the model incorrectly spots examples as fraud</p></li>
<li><p>false negatives (type II errors), where it’s missing to spot fraud examples</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">ConfusionMatrixDisplay</span>  

<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;Fraud&quot;</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="which-types-of-errors-would-be-most-critical-for-the-bank-to-address">
<h3>Which types of errors would be most critical for the bank to address?<a class="headerlink" href="#which-types-of-errors-would-be-most-critical-for-the-bank-to-address" title="Link to this heading">#</a></h3>
<p><br><br><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="n">plot_confusion_matrix_example</span><span class="p">(</span><span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Perfect prediction has all values down the diagonal</p></li>
<li><p>Off diagonal entries can often tell us about what is being mis-predicted</p></li>
</ul>
</section>
<section id="what-is-positive-and-negative">
<h3>What is “positive” and “negative”?<a class="headerlink" href="#what-is-positive-and-negative" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Two kinds of binary classification problems</p>
<ul>
<li><p>Distinguishing between two classes</p></li>
<li><p>Spotting a class (spot fraud transaction, spot spam, spot disease)</p></li>
</ul>
</li>
<li><p>In case of spotting problems, the thing that we are interested in spotting is considered “positive”.</p></li>
<li><p>Above we wanted to spot fraudulent transactions and so they are “positive”.</p></li>
</ul>
<p>You can get a numpy array of confusion matrix as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Confusion matrix for fraud data set&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="confusion-matrix-with-cross-validation">
<h3>Confusion matrix with cross-validation<a class="headerlink" href="#confusion-matrix-with-cross-validation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>You can also calculate confusion matrix with cross-validation using the <code class="docutils literal notranslate"><span class="pre">cross_val_predict</span></code> method.</p></li>
<li><p>But then you cannot plot it in a nice format.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_predict</span>

<span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">cross_val_predict</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p><br><br><br><br></p>
</section>
</section>
<section id="precision-recall-f1-score">
<h2>Precision, recall, f1 score<a class="headerlink" href="#precision-recall-f1-score" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>We have been using <code class="docutils literal notranslate"><span class="pre">.score</span></code> to assess our models, which returns accuracy by default.</p></li>
<li><p>Accuracy is misleading when we have class imbalance.</p></li>
<li><p>We need other metrics to assess our models.</p></li>
</ul>
<ul class="simple">
<li><p>We’ll discuss three commonly used metrics which are based on confusion matrix:</p>
<ul>
<li><p>recall</p></li>
<li><p>precision</p></li>
<li><p>f1 score</p></li>
</ul>
</li>
<li><p>Note that these metrics will only help us assess our model.</p></li>
<li><p>Later we’ll talk about a few ways to address class imbalance problem.</p></li>
</ul>
<section id="precision-and-recall-toy-example">
<h3>Precision and recall: toy example<a class="headerlink" href="#precision-and-recall-toy-example" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Imagine that your model has identified everything outside the circle as non-fraud and everything inside the circle as fraud.</p></li>
</ul>
<p><img alt="" src="../../../_images/precision-recall.png" /></p>
<p><img alt="" src="../../../_images/fraud-precision-recall.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>

<span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">pipe_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">TN</span><span class="p">,</span> <span class="n">FP</span><span class="p">,</span> <span class="n">FN</span><span class="p">,</span> <span class="n">TP</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cm</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="precision">
<h3>Precision<a class="headerlink" href="#precision" title="Link to this heading">#</a></h3>
<p>Among the positive examples you identified, how many were actually positive?</p>
<div class="math notranslate nohighlight">
\[ precision = \frac{TP}{TP+FP}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cm</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TP = </span><span class="si">%0.4f</span><span class="s2">, FP = </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FP</span><span class="p">))</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Precision: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">precision</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="recall">
<h3>Recall<a class="headerlink" href="#recall" title="Link to this heading">#</a></h3>
<p>Among all positive examples, how many did you identify correctly?
$<span class="math notranslate nohighlight">\( recall = \frac{TP}{TP+FN} = \frac{TP}{\#positives} \)</span>$</p>
<ul class="simple">
<li><p>Also called as sensitivity, coverage, true positive rate (TPR)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TP = </span><span class="si">%0.4f</span><span class="s2">, FN = </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">TP</span><span class="p">,</span> <span class="n">FN</span><span class="p">))</span>
<span class="n">recall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span><span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Recall: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">recall</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="f1-score">
<h3>F1-score<a class="headerlink" href="#f1-score" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>F1-score combines precision and recall to give one score, which could be used in hyperparameter optimization, for instance.</p></li>
<li><p>F1-score is a harmonic mean of precision and recall.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ f1 = 2 \times \frac{ precision \times recall}{precision + recall}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;precision: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">precision</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;recall: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">recall</span><span class="p">))</span>
<span class="n">f1_score</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">precision</span> <span class="o">*</span> <span class="n">recall</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">precision</span> <span class="o">+</span> <span class="n">recall</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1: </span><span class="si">%0.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">f1_score</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s look at all metrics at once on our dataset.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Calculate evaluation metrics by ourselves</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;calculation&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;error&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;precision&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;recall&quot;</span><span class="p">:</span> <span class="p">[],</span>
    <span class="s2">&quot;f1 score&quot;</span><span class="p">:</span> <span class="p">[],</span>
<span class="p">}</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;calculation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;manual&quot;</span><span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">TP</span> <span class="o">+</span> <span class="n">TN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;error&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">TN</span> <span class="o">+</span> <span class="n">FP</span> <span class="o">+</span> <span class="n">FN</span> <span class="o">+</span> <span class="n">TP</span><span class="p">))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">precision</span><span class="p">)</span>  <span class="c1"># TP / (TP + FP)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall</span><span class="p">)</span>  <span class="c1"># TP / (TP + FN)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;f1 score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">)</span>  <span class="c1"># (2 * precision * recall) / (precision + recall)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> has functions for <a class="reference external" href="https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics">these metrics</a>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>

<span class="n">data</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;error&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
    <span class="n">precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">zero_division</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;f1 score&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)))</span>
<span class="n">data</span><span class="p">[</span><span class="s2">&quot;calculation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;sklearn&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">set_index</span><span class="p">([</span><span class="s2">&quot;calculation&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>The scores match.</p>
</section>
<section id="classification-report">
<h3>Classification report<a class="headerlink" href="#classification-report" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>There is a convenient function called <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> in <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> which gives this info.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span><span class="o">.</span><span class="n">classes_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>

<span class="nb">print</span><span class="p">(</span>
    <span class="n">classification_report</span><span class="p">(</span>
        <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">),</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non-fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="interim-summary">
<h3>Interim summary<a class="headerlink" href="#interim-summary" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Accuracy is misleading when you have class imbalance.</p></li>
<li><p>A confusion matrix provides a way to break down errors made by our model.</p></li>
<li><p>We looked at three metrics based on confusion matrix:</p>
<ul>
<li><p>precision, recall, f1-score.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Note that what you consider “positive” (fraud in our case) is important when calculating precision, recall, and f1-score.</p></li>
<li><p>If you flip what is considered positive or negative, we’ll end up with different TP, FP, TN, FN, and hence different precision, recall, and f1-scores.</p></li>
</ul>
</section>
<section id="evalution-metrics-overview">
<h3>Evalution metrics overview<a class="headerlink" href="#evalution-metrics-overview" title="Link to this heading">#</a></h3>
<p>There is a lot of terminology here.</p>
<p><img alt="" src="../../../_images/evaluation-metrics.png" /></p>
</section>
<section id="cross-validation-with-different-metrics">
<h3>Cross validation with different metrics<a class="headerlink" href="#cross-validation-with-different-metrics" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>We can pass different evaluation metrics with <code class="docutils literal notranslate"><span class="pre">scoring</span></code> argument of <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;accuracy&quot;</span><span class="p">,</span>
    <span class="s2">&quot;f1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;recall&quot;</span><span class="p">,</span>
    <span class="s2">&quot;precision&quot;</span><span class="p">,</span>
<span class="p">]</span>  <span class="c1"># scoring can be a string, a list, or a dictionary</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">pipe</span><span class="p">,</span> <span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>You can also create <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html">your own scoring function</a> and pass it to <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>.</p></li>
</ul>
<p><br><br></p>
</section>
</section>
<section id="precision-recall-curve">
<h2>Precision-recall curve<a class="headerlink" href="#precision-recall-curve" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Confusion matrix provides a detailed break down of the errors made by the model.</p></li>
<li><p>But when creating a confusion matrix, we are using “hard” predictions.</p></li>
<li><p>Most classifiers in <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> provide <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method (or <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>) which provides degree of certainty about predictions by the classifier.</p></li>
<li><p>Can we explore the degree of uncertainty to understand and improve the model performance?</p></li>
</ul>
<p>Let’s revisit the classification report on our fraud detection example.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">pipe_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non-fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<p>By default, predictions use the threshold of 0.5. If <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> &gt; 0.5, predict “fraud” else predict “non-fraud”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.50</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non-fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Suppose for your business it is more costly to miss fraudulent transactions and suppose you want to achieve a recall of at least 75% for the “fraud” class.</p></li>
<li><p>One way to do this is by changing the threshold of <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">predict</span></code> returns 1 when <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>’s probabilities are above 0.5 for the “fraud” class.</p></li>
</ul>
</li>
</ul>
<p><strong>Key idea: what if we threshold the probability at a smaller value so that we identify more examples as “fraud” examples?</strong></p>
<p>Let’s lower the threshold to 0.1. In other words, predict the examples as “fraud” if <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> &gt; 0.1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred_lower_threshold</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.1</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred_lower_threshold</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<section id="operating-point">
<h3>Operating point<a class="headerlink" href="#operating-point" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Now our recall for “fraud” class is &gt;= 0.75.</p></li>
<li><p>Setting a requirement on a classifier (e.g., recall of &gt;= 0.75) is called setting the <strong>operating point</strong>.</p></li>
<li><p>It’s usually driven by business goals and is useful to make performance guarantees to customers.</p></li>
</ul>
</section>
<section id="precision-recall-tradeoff">
<h3>Precision/Recall tradeoff<a class="headerlink" href="#precision-recall-tradeoff" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>But there is a trade-off between precision and recall.</p></li>
<li><p>If you identify more things as “fraud”, recall is going to increase but there are likely to be more false positives.</p></li>
</ul>
<p>Let’s sweep through different thresholds.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresholds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">thresholds</span>
</pre></div>
</div>
</div>
</div>
<p>You need to install <code class="docutils literal notranslate"><span class="pre">panel</span></code> package in order to run the code below locally. See the documentation <a class="reference external" href="https://pyviz-dev.github.io/panel/getting_started/installation.html#jupyterlab-and-classic-notebook">here</a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">-c</span> <span class="pre">pyviz</span> <span class="pre">panel</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">panel</span> <span class="k">as</span> <span class="nn">pn</span>
<span class="kn">from</span> <span class="nn">panel</span> <span class="kn">import</span> <span class="n">widgets</span>
<span class="kn">from</span> <span class="nn">panel.interact</span> <span class="kn">import</span> <span class="n">interact</span>

<span class="n">pn</span><span class="o">.</span><span class="n">extension</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">threshold</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">preds</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;threshold&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="s1">&#39;Precision&#39;</span><span class="p">:</span> <span class="n">precision</span><span class="p">,</span> <span class="s1">&#39;recall&#39;</span><span class="p">:</span> <span class="n">recall</span><span class="p">}</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">d</span><span class="p">)</span>

<span class="n">interact</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span><span class="o">.</span><span class="n">embed</span><span class="p">(</span><span class="n">max_opts</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="decreasing-the-threshold">
<h3>Decreasing the threshold<a class="headerlink" href="#decreasing-the-threshold" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Decreasing the threshold means a lower bar for predicting fraud.</p>
<ul>
<li><p>You are willing to risk more false positives in exchange of more true positives.</p></li>
<li><p>Recall would either stay the same or go up and precision is likely to go down</p></li>
<li><p>Occasionally, precision may increase if all the new examples after decreasing the threshold are TPs.</p></li>
</ul>
</li>
</ul>
</section>
<section id="increasing-the-threshold">
<h3>Increasing the threshold<a class="headerlink" href="#increasing-the-threshold" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Increasing the threshold means a higher bar for predicting fraud.</p>
<ul>
<li><p>Recall would go down or stay the same but precision is likely to go up</p></li>
<li><p>Occasionally, precision may go down if TP decrease but FP do not decrease.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id1">
<h3>Precision-recall curve<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>Often, when developing a model, it’s not always clear what the operating point will be and to understand the model better, it’s informative to look at all possible thresholds and corresponding trade-offs of precision and recall in a plot.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_curve</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;logistic regression: PR curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Recall&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)),</span>
    <span class="n">recall_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)),</span>
    <span class="s2">&quot;or&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Each point in the curve corresponds to a possible threshold of the <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> output.</p></li>
<li><p>We can achieve a recall of 0.8 at a precision of 0.4.</p></li>
<li><p>The red dot marks the point corresponding to the threshold 0.5.</p></li>
<li><p>The top-right would be a perfect classifier (precision = recall = 1).</p></li>
</ul>
<ul class="simple">
<li><p>The threshold is not shown here, but it’s going from 0 (upper-left) to 1 (lower right).</p></li>
<li><p>At a threshold of 0 (upper left), we are classifying everything  as “fraud”.</p></li>
<li><p>Raising the threshold increases the precision but at the expense of lowering the recall.</p></li>
<li><p>At the extreme right, where the threshold is 1, we get into the situation where all the examples classified as “fraud” are actually “fraud”; we have no false positives.</p></li>
<li><p>Here we have a high precision but lower recall.</p></li>
<li><p>Usually the goal is to keep recall high as precision goes up.</p></li>
</ul>
</section>
<section id="ap-score">
<h3>AP score<a class="headerlink" href="#ap-score" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Often it’s useful to have one number summarizing the PR plot (e.g., in hyperparameter optimization)</p></li>
<li><p>One way to do this is by computing the area under the PR curve.</p></li>
<li><p>This is called <strong>average precision</strong> (AP score)</p></li>
<li><p>AP score has a value between 0 (worst) and 1 (best).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">average_precision_score</span>

<span class="n">ap_lr</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average precision of logistic regression: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ap_lr</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>You can also use the following handy function of <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> to get the PR curve and the corresponding AP score.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">PrecisionRecallDisplay</span>

<span class="n">PrecisionRecallDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="ap-vs-f1-score">
<h3>AP vs. F1-score<a class="headerlink" href="#ap-vs-f1-score" title="Link to this heading">#</a></h3>
<p>It is very important to note this distinction:</p>
<ul class="simple">
<li><p>F1 score is for a given threshold and measures the quality of <code class="docutils literal notranslate"><span class="pre">predict</span></code>.</p></li>
<li><p>AP score is a summary across thresholds and measures the quality of <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>.</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Remember to pick the desired threshold based on the results on the validation set and <strong>not</strong> on the test set.</p>
</div>
</section>
<section id="a-few-comments-on-pr-curve">
<h3>A few comments on PR curve<a class="headerlink" href="#a-few-comments-on-pr-curve" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Different classifiers might work well in different parts of the curve, i.e., at different operating points.</p></li>
<li><p>We can compare PR curves of different classifiers to understand these differences.</p></li>
<li><p>Let’s create PR curves for SVC and Logistic Regression.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_svc</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SVC</span><span class="p">())</span>

<span class="n">pipe_svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">pipe_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>How to get precision and recall for different thresholds?</p>
<ul class="simple">
<li><p>Use the function <code class="docutils literal notranslate"><span class="pre">precision_recall_curve</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision_lr</span><span class="p">,</span> <span class="n">recall_lr</span><span class="p">,</span> <span class="n">thresholds_lr</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="optional-some-more-details">
<h3>(Optional) Some more details<a class="headerlink" href="#optional-some-more-details" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>How are the thresholds and the precision and recall at the default threshold are calculated?</p></li>
</ul>
<p>How many thresholds?</p>
<ul class="simple">
<li><p>It uses <code class="docutils literal notranslate"><span class="pre">n_thresholds</span></code> where <code class="docutils literal notranslate"><span class="pre">n_thresholds</span></code> is the number of unique <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> scores in our dataset.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>For each threshold, precision and recall are calculated.</p></li>
<li><p>The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresholds_lr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">precision_lr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">recall_lr</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">precision_lr</span><span class="p">,</span> <span class="n">recall_lr</span><span class="p">,</span> <span class="n">thresholds_lr</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">precision_svc</span><span class="p">,</span> <span class="n">recall_svc</span><span class="p">,</span> <span class="n">thresholds_svc</span> <span class="o">=</span> <span class="n">precision_recall_curve</span><span class="p">(</span>
    <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For logistic regression, what’s the index of the threshold that is closest to the default threshold of 0.5?</p>
<ul class="simple">
<li><p>We are subtracting 0.5 from the thresholds so that</p>
<ul>
<li><p>the numbers close to 0 become -0.5</p></li>
<li><p>the numbers close to 1 become 0.5</p></li>
<li><p>the numbers close to 0.5 become 0</p></li>
</ul>
</li>
<li><p>After this transformation, we are interested in the threshold index where the number is close to 0. So we take  absolute values and argmin.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">close_default_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_lr</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>SVC doesn’t have <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code>. Instead it has something called <code class="docutils literal notranslate"><span class="pre">decision_function</span></code>. The index of the threshold that is closest to 0 of decision function is the default threshold in SVC.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">close_zero_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_svc</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="pr-curves-for-logistic-regression-and-svc">
<h3>PR curves for logistic regression and SVC<a class="headerlink" href="#pr-curves-for-logistic-regression-and-svc" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_svc</span><span class="p">,</span> <span class="n">recall_svc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;svc&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">precision_lr</span><span class="p">,</span> <span class="n">recall_lr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;logistic regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">precision_svc</span><span class="p">[</span><span class="n">close_zero_svm</span><span class="p">],</span>
    <span class="n">recall_svc</span><span class="p">[</span><span class="n">close_zero_svm</span><span class="p">],</span>
    <span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;default threshold svc&quot;</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">precision_lr</span><span class="p">[</span><span class="n">close_default_lr</span><span class="p">],</span>
    <span class="n">recall_lr</span><span class="p">[</span><span class="n">close_default_lr</span><span class="p">],</span>
    <span class="s2">&quot;*&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;default threshold logistic regression&quot;</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Precision&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Recall&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<section id="which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression">
<h4>Which model is doing better in this scenario: SVC or Logistic Regression?<a class="headerlink" href="#which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression" title="Link to this heading">#</a></h4>
<p><br><br><br><br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc_preds</span> <span class="o">=</span> <span class="n">pipe_svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="n">lr_preds</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1_score of logistic regression: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">lr_preds</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1_score of svc: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">svc_preds</span><span class="p">)))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ap_lr</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ap_svc</span> <span class="o">=</span> <span class="n">average_precision_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_valid</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average precision of logistic regression: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ap_lr</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average precision of SVC: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ap_svc</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Comparing the precision-recall curves provide us a detail insight compared to f1 score.</p></li>
<li><p>For example, F1 scores for SVC and logistic regressions are pretty similar. In fact, f1 score of logistic regression is a tiny bit better.</p></li>
<li><p>But when we look at the PR curve, we see that SVC is doing better than logistic regression for most of the other thresholds.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
</section>
<section id="receiver-operating-characteristic-roc-curve">
<h2>Receiver Operating Characteristic (ROC) curve<a class="headerlink" href="#receiver-operating-characteristic-roc-curve" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Another commonly used tool to analyze the behavior of classifiers at different thresholds.</p></li>
<li><p>Similar to PR curve, it considers all possible thresholds for a given classifier given by <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> but instead of precision and recall it plots false positive rate (FPR) and true positive rate (TPR or recall).
$<span class="math notranslate nohighlight">\( TPR = \frac{TP}{TP + FN}\)</span>$</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ FPR  = \frac{FP}{FP + TN}\]</div>
<ul class="simple">
<li><p>TPR <span class="math notranslate nohighlight">\(\rightarrow\)</span> Fraction of true positives out of all positive examples.</p></li>
<li><p>FPR <span class="math notranslate nohighlight">\(\rightarrow\)</span> Fraction of false positives out of all negative examples.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>

<span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;ROC Curve&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;FPR&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;TPR (recall)&quot;</span><span class="p">)</span>

<span class="n">default_threshold</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr</span><span class="p">[</span><span class="n">default_threshold</span><span class="p">],</span>
    <span class="n">tpr</span><span class="p">[</span><span class="n">default_threshold</span><span class="p">],</span>
    <span class="s2">&quot;or&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;threshold 0.5&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Different points on the ROC curve represent different classification thresholds. The curve starts at (0,0) and ends at (1, 1).</p>
<ul>
<li><p>(0, 0) represents the threshold that classifies everything as the negative class</p></li>
<li><p>(1, 1) represents the threshold that classifies everything as the positive class</p></li>
</ul>
</li>
<li><p>The ideal curve is close to the top left</p>
<ul>
<li><p>Ideally, you want a classifier with high recall while keeping low false positive rate.</p></li>
</ul>
</li>
<li><p>The red dot corresponds to the threshold of 0.5, which is used by predict.</p></li>
<li><p>We see that compared to the default threshold, we can achieve a better recall of around 0.8 without increasing FPR.</p></li>
</ul>
<p>Let’s compare ROC curve of different classifiers.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fpr_lr</span><span class="p">,</span> <span class="n">tpr_lr</span><span class="p">,</span> <span class="n">thresholds_lr</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="n">fpr_svc</span><span class="p">,</span> <span class="n">tpr_svc</span><span class="p">,</span> <span class="n">thresholds_svc</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span>
    <span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">close_default_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_lr</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="n">close_zero_svm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">thresholds_svc</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_svc</span><span class="p">,</span> <span class="n">tpr_svc</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;svc&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr_lr</span><span class="p">,</span> <span class="n">tpr_lr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;logistic regression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr_svc</span><span class="p">[</span><span class="n">close_zero_svm</span><span class="p">],</span>
    <span class="n">tpr_svc</span><span class="p">[</span><span class="n">close_zero_svm</span><span class="p">],</span>
    <span class="s2">&quot;o&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;default threshold svc&quot;</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">fpr_lr</span><span class="p">[</span><span class="n">close_default_lr</span><span class="p">],</span>
    <span class="n">tpr_lr</span><span class="p">[</span><span class="n">close_default_lr</span><span class="p">],</span>
    <span class="s2">&quot;*&quot;</span><span class="p">,</span>
    <span class="n">markersize</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;default threshold logistic regression&quot;</span><span class="p">,</span>
    <span class="n">c</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;False positive rate&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;True positive rate (Recall)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<section id="area-under-the-curve-auc">
<h3>Area under the curve (AUC)<a class="headerlink" href="#area-under-the-curve-auc" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>AUC provides a single meaningful number for the model performance.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="n">roc_lr</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">roc_svc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">pipe_svc</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">X_valid</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC for LR: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_lr</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AUC for SVC: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">roc_svc</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>AUC of 0.5 means random chance.</p></li>
<li><p>AUC can be interpreted as evaluating the <strong>ranking</strong> of positive examples.</p></li>
<li><p>What’s the probability that a randomly picked positive point has a higher score according to the classifier than a randomly picked point from the negative class.</p></li>
<li><p>AUC of 1.0 means all positive points have a higher score than all negative points.</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>For classification problems with imbalanced classes, using AP score or AUC is often much more meaningful than using accuracy.</p>
</div>
<p>Similar to <code class="docutils literal notranslate"><span class="pre">PrecisionRecallCurveDisplay</span></code>, there is a <code class="docutils literal notranslate"><span class="pre">RocCurveDisplay</span></code> function in sklearn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">RocCurveDisplay</span>

<span class="n">RocCurveDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="let-s-look-at-all-the-scores-at-once">
<h3>Let’s look at all the scores at once<a class="headerlink" href="#let-s-look-at-all-the-scores-at-once" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">]</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Check out <a class="reference external" href="https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation">these visualization</a> on ROC and AUC.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">See also</p>
<p>Check out how to plot ROC with cross-validation <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html">here</a>.</p>
</div>
<p><br><br><br><br></p>
</section>
</section>
<section id="dealing-with-class-imbalance-video">
<h2>Dealing with class imbalance [<a class="reference external" href="https://www.youtube.com/watch?v=jHaKRCFb6Qw">video</a>]<a class="headerlink" href="#dealing-with-class-imbalance-video" title="Link to this heading">#</a></h2>
<section id="class-imbalance-in-training-sets">
<h3>Class imbalance in training sets<a class="headerlink" href="#class-imbalance-in-training-sets" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>This typically refers to having many more examples of one class than another in one’s training set.</p></li>
<li><p>Real world data is often imbalanced.</p>
<ul>
<li><p>Our Credit Card Fraud dataset is imbalanced.</p></li>
<li><p>Ad clicking data is usually drastically imbalanced. (Only around ~0.01% ads are clicked.)</p></li>
<li><p>Spam classification datasets are also usually imbalanced.</p></li>
</ul>
</li>
</ul>
</section>
<section id="addressing-class-imbalance">
<h3>Addressing class imbalance<a class="headerlink" href="#addressing-class-imbalance" title="Link to this heading">#</a></h3>
<p>A very important question to ask yourself: “Why do I have a class imbalance?”</p>
<ul class="simple">
<li><p>Is it because one class is much more rare than the other?</p>
<ul>
<li><p>If it’s just because one is more rare than the other, you need to ask whether you care about one type of error more than the other.</p></li>
</ul>
</li>
<li><p>Is it because of my data collection methods?</p>
<ul>
<li><p>If it’s the data collection, then that means <em>your test and training data come from different distributions</em>!</p></li>
</ul>
</li>
</ul>
<p>In some cases, it may be fine to just ignore the class imbalance.</p>
</section>
<section id="which-type-of-error-is-more-important">
<h3>Which type of error is more important?<a class="headerlink" href="#which-type-of-error-is-more-important" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>False positives (FPs) and false negatives (FNs) have quite different real-world consequences.</p></li>
<li><p>In PR curve and ROC curve, we saw how changing the prediction threshold can change FPs and FNs.</p></li>
<li><p>We can then pick the threshold that’s appropriate for our problem.</p></li>
<li><p>Example: if we want high recall, we may use a lower threshold (e.g., a threshold of 0.1). We’ll then catch more fraudulent transactions.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">pipe_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non-fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.10</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;non-fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="handling-imbalance">
<h3>Handling imbalance<a class="headerlink" href="#handling-imbalance" title="Link to this heading">#</a></h3>
<p>Can we change the model itself rather than changing the threshold so that it takes into account the errors that are important to us?</p>
<p>There are two common approaches for this:</p>
<ul class="simple">
<li><p><strong>Changing the data (optional)</strong> (not covered in this course)</p>
<ul>
<li><p>Undersampling</p></li>
<li><p>Oversampling</p>
<ul>
<li><p>Random oversampling</p></li>
<li><p>SMOTE</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Changing the training procedure</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></p></li>
</ul>
</li>
</ul>
</section>
<section id="changing-the-training-procedure">
<h3>Changing the training procedure<a class="headerlink" href="#changing-the-training-procedure" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>All <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> classifiers have a parameter called <code class="docutils literal notranslate"><span class="pre">class_weight</span></code>.</p></li>
<li><p>This allows you to specify that one class is more important than another.</p></li>
<li><p>For example, maybe a false negative is 10x more problematic than a false positive.</p></li>
</ul>
</section>
<section id="example-class-weight-parameter-of-sklearn-logisticregression">
<h3>Example: <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">sklearn</span> <span class="pre">LogisticRegression</span></code><a class="headerlink" href="#example-class-weight-parameter-of-sklearn-logisticregression" title="Link to this heading">#</a></h3>
<blockquote>
<div><p>class sklearn.linear_model.LogisticRegression(penalty=’l2’, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, <strong>class_weight=None</strong>, random_state=None, solver=’lbfgs’, max_iter=100, multi_class=’auto’, verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)</p>
</div></blockquote>
<blockquote>
<div><p>class_weight: dict or ‘balanced’, default=None</p>
</div></blockquote>
<blockquote>
<div><p>Weights associated with classes in the form {class_label: weight}. If not given, all classes are supposed to have weight one.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">IPython</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html&quot;</span>
<span class="n">IPython</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">IFrame</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">650</span><span class="p">,</span> <span class="n">src</span><span class="o">=</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot_confusion_matrix(</span>
<span class="c1">#     pipe_lr,</span>
<span class="c1">#     X_valid,</span>
<span class="c1">#     y_valid,</span>
<span class="c1">#     display_labels=[&quot;Non fraud&quot;, &quot;fraud&quot;],</span>
<span class="c1">#     values_format=&quot;d&quot;,</span>
<span class="c1">#     cmap=plt.cm.Blues,</span>
<span class="c1"># );</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">],</span> <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span><span class="o">.</span><span class="n">named_steps</span><span class="p">[</span><span class="s2">&quot;logisticregression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s set “fraud” class a weight of 10.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_weight</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="p">{</span><span class="mi">0</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span> <span class="mi">10</span><span class="p">})</span>
<span class="p">)</span>
<span class="n">pipe_lr_weight</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe_lr_weight</span><span class="p">,</span>
    <span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">],</span>
    <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Notice we’ve reduced false negatives and predicted more Fraud this time.</p></li>
<li><p>This was equivalent to saying give 10x more “importance” to fraud class.</p></li>
<li><p>Note that as a consequence we are also increasing false positives.</p></li>
</ul>
</section>
<section id="class-weight-balanced">
<h3><code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code><a class="headerlink" href="#class-weight-balanced" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A useful setting is <code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code>.</p></li>
<li><p>This sets the weights so that the classes are “equal”.</p></li>
</ul>
<blockquote>
<div><p>class_weight: dict, ‘balanced’ or None
If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). If a dictionary is given, keys are classes and values are corresponding class weights. If None is given, the class weights will be uniform.</p>
</div></blockquote>
<blockquote>
<div><p>sklearn.utils.class_weight.compute_class_weight(class_weight, classes, y)</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_balanced</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pipe_lr_balanced</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span>
    <span class="n">pipe_lr_balanced</span><span class="p">,</span>
    <span class="n">X_valid</span><span class="p">,</span>
    <span class="n">y_valid</span><span class="p">,</span>
    <span class="n">display_labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Non fraud&quot;</span><span class="p">,</span> <span class="s2">&quot;fraud&quot;</span><span class="p">],</span>
    <span class="n">values_format</span><span class="o">=</span><span class="s2">&quot;d&quot;</span><span class="p">,</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>We have reduced false negatives but we have many more false positives now …</p>
</section>
<section id="are-we-doing-better-with-class-weight-balanced">
<h3>Are we doing better with <code class="docutils literal notranslate"><span class="pre">class_weight=&quot;balanced&quot;</span></code>?<a class="headerlink" href="#are-we-doing-better-with-class-weight-balanced" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">comp_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">))</span>
<span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">]</span>
<span class="n">orig_scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr_balanced</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;f1&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">,</span> <span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">]</span>
<span class="n">bal_scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">pipe_lr_balanced</span><span class="p">,</span> <span class="n">X_train_big</span><span class="p">,</span> <span class="n">y_train_big</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
<span class="n">comp_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Original&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">orig_scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
    <span class="s2">&quot;class_weight=&#39;balanced&#39;&quot;</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">bal_scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">comp_dict</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">bal_scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Recall is much better but precision has dropped a lot; we have many false positives.</p></li>
<li><p>You could also optimize <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> using hyperparameter optimization for your specific problem.</p></li>
</ul>
<ul class="simple">
<li><p>Changing the class weight will <strong>generally reduce accuracy</strong>.</p></li>
<li><p>The original model was trying to maximize accuracy.</p></li>
<li><p>Now you’re telling it to do something different.</p></li>
<li><p>But that can be fine, accuracy isn’t the only metric that matters.</p></li>
</ul>
</section>
<section id="stratified-splits">
<h3>Stratified Splits<a class="headerlink" href="#stratified-splits" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>A similar idea of “balancing” classes can be applied to data splits.</p></li>
<li><p>We have the same option in <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> with the <code class="docutils literal notranslate"><span class="pre">stratify</span></code> argument.</p></li>
<li><p>By default it splits the data so that if we have 10% negative examples in total, then each split will have 10% negative examples.</p></li>
</ul>
<ul class="simple">
<li><p>If you are carrying out cross validation using <code class="docutils literal notranslate"><span class="pre">cross_validate</span></code>, by default it uses <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"><code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a>. From the documentation:</p></li>
</ul>
<blockquote>
<div><p>This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.</p>
</div></blockquote>
<ul class="simple">
<li><p>In other words, if we have 10% negative examples in total, then each fold will have 10% negative examples.</p></li>
</ul>
</section>
<section id="is-stratifying-a-good-idea">
<h3>Is stratifying a good idea?<a class="headerlink" href="#is-stratifying-a-good-idea" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Well, it’s no longer a random sample, which is probably theoretically bad, but not that big of a deal.</p></li>
<li><p>If you have many examples, it shouldn’t matter as much.</p></li>
<li><p>It can be especially useful in multi-class, say if you have one class with very few cases.</p></li>
<li><p>In general, these are difficult questions.</p></li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="optional-changing-the-data">
<h2>(Optional) Changing the data<a class="headerlink" href="#optional-changing-the-data" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>Undersampling</p></li>
<li><p>Oversampling</p>
<ul>
<li><p>Random oversampling</p></li>
<li><p>SMOTE</p></li>
</ul>
</li>
</ul>
<p>We cannot use sklearn pipelines because of some API related problems. But there is something called <a class="reference external" href="https://imbalanced-learn.org/stable/"><code class="docutils literal notranslate"><span class="pre">imbalance</span> <span class="pre">learn</span></code></a>, which is an extension of the <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> API that allows us to resample. It’s already in our course environment. If you don’t have the course environment installed, you can install it in your environment with this command:</p>
<p><code class="docutils literal notranslate"><span class="pre">conda</span> <span class="pre">install</span> <span class="pre">-c</span> <span class="pre">conda-forge</span> <span class="pre">imbalanced-learn</span></code></p>
<section id="undersampling">
<h3>Undersampling<a class="headerlink" href="#undersampling" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imblearn</span>
<span class="kn">from</span> <span class="nn">imblearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span> <span class="k">as</span> <span class="n">make_imb_pipeline</span>
<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>

<span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">()</span>
<span class="n">X_train_subsample</span><span class="p">,</span> <span class="n">y_train_subsample</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train_subsample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train_subsample</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>

<span class="kn">from</span> <span class="nn">imblearn.under_sampling</span> <span class="kn">import</span> <span class="n">RandomUnderSampler</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">class_sep</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">],</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">flip_y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original dataset shape </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
<span class="n">rus</span> <span class="o">=</span> <span class="n">RandomUnderSampler</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X_res</span><span class="p">,</span> <span class="n">y_res</span> <span class="o">=</span> <span class="n">rus</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Resampled dataset shape </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">Counter</span><span class="p">(</span><span class="n">y_res</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">undersample_pipe</span> <span class="o">=</span> <span class="n">make_imb_pipeline</span><span class="p">(</span>
    <span class="n">RandomUnderSampler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">undersample_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
</section>
<section id="oversampling">
<h3>Oversampling<a class="headerlink" href="#oversampling" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>Random oversampling with replacement</p></li>
<li><p>SMOTE: Synthetic Minority Over-sampling Technique</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">RandomOverSampler</span>

<span class="n">ros</span> <span class="o">=</span> <span class="n">RandomOverSampler</span><span class="p">()</span>
<span class="n">X_train_oversample</span><span class="p">,</span> <span class="n">y_train_oversample</span> <span class="o">=</span> <span class="n">ros</span><span class="o">.</span><span class="n">fit_resample</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train_oversample</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y_train_oversample</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">oversample_pipe</span> <span class="o">=</span> <span class="n">make_imb_pipeline</span><span class="p">(</span>
    <span class="n">RandomOverSampler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">oversample_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p><br><br></p>
<section id="smote-synthetic-minority-over-sampling-technique">
<h4><a class="reference external" href="https://arxiv.org/pdf/1106.1813.pdf">SMOTE: Synthetic Minority Over-sampling Technique</a><a class="headerlink" href="#smote-synthetic-minority-over-sampling-technique" title="Link to this heading">#</a></h4>
<p><a class="reference external" href="https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html">sklearn SMOTE</a></p>
<ul class="simple">
<li><p>Create “synthetic” examples rather than by over-sampling with replacement.</p></li>
<li><p>Inspired by a technique of data augmentation that proved successful in handwritten character recognition.</p></li>
<li><p>The minority class is over-sampled by taking each minority class sample and introducing synthetic examples along the line segments joining any/all of the <span class="math notranslate nohighlight">\(k\)</span> minority class nearest neighbors.</p></li>
<li><p><span class="math notranslate nohighlight">\(k\)</span> is chosen depending upon the amount of over-sampling required.</p></li>
</ul>
</section>
<section id="smote-idea">
<h4>SMOTE idea<a class="headerlink" href="#smote-idea" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>Take the difference between the feature vector (sample) under consideration and its nearest neighbor.</p></li>
<li><p>Multiply this difference by a random number between 0 and 1, and add it to the feature vector under consideration.</p></li>
<li><p>This causes the selection of a random point along the line segment between two specific features.</p></li>
<li><p>This approach effectively forces the decision region of the minority class to become more general.</p></li>
</ul>
<p><img alt="" src="../../../_images/SMOTE_doccam.png" /></p>
<!-- <img src="img/SMOTE_doccam.png" width="600" height="600"> --></section>
</section>
<section id="using-smote">
<h3>Using SMOTE<a class="headerlink" href="#using-smote" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p>You need to <a class="reference external" href="https://imbalanced-learn.org/stable/index.html"><code class="docutils literal notranslate"><span class="pre">imbalanced-learn</span></code></a></p></li>
</ul>
<blockquote>
<div><p>class imblearn.over_sampling.SMOTE(sampling_strategy=’auto’, random_state=None, k_neighbors=5, m_neighbors=’deprecated’, out_step=’deprecated’, kind=’deprecated’, svm_estimator=’deprecated’, n_jobs=1, ratio=None)</p>
</div></blockquote>
<blockquote>
<div><p>Class to perform over-sampling using SMOTE.</p>
</div></blockquote>
<blockquote>
<div><p>This object is an implementation of SMOTE - Synthetic Minority Over-sampling Technique as presented in <a class="reference external" href="https://arxiv.org/pdf/1106.1813.pdf">this paper</a>.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">imblearn.over_sampling</span> <span class="kn">import</span> <span class="n">SMOTE</span>

<span class="n">smote_pipe</span> <span class="o">=</span> <span class="n">make_imb_pipeline</span><span class="p">(</span>
    <span class="n">SMOTE</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span>
    <span class="n">smote_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;roc_auc&quot;</span><span class="p">,</span> <span class="s2">&quot;average_precision&quot;</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>We got higher average precision score with SMOTE in this case.</p></li>
</ul>
<ul class="simple">
<li><p>These are rather simple approaches to tackle class imbalance.</p></li>
<li><p>If you have a problem such as fraud detection problem where you want to spot rare events, you can think of this problem as anomaly detection problem and use algorithms such as isolation forests.</p></li>
<li><p>If you are interested in this area, it might be worth checking out this book on this topic. (I’ve not read it.)</p>
<ul>
<li><p>Imbalanced Learning: Foundations, Algorithms, and Applications</p></li>
<li><p>It’s available via UBC library.</p></li>
</ul>
</li>
</ul>
<p><br><br><br><br></p>
</section>
</section>
<section id="ml-fairness-activity-5-mins">
<h2>ML fairness activity (~5 mins)<a class="headerlink" href="#ml-fairness-activity-5-mins" title="Link to this heading">#</a></h2>
<p>AI/ML systems can give the illusion of objectivity as they are derived from seemingly unbiased data &amp; algorithm. However, human are inherently biased and AI/ML systems, if not carefully evaluated, can even further amplify the existing inequities and systemic bias in our society.</p>
<p>How do we make sure our AI/ML systems are <em>fair</em>? Which metrics can we use to quantify ‘fairness’ in AI/ML systems?</p>
<p>Let’s examine this on <a class="reference external" href="https://www.kaggle.com/uciml/adult-census-income">the adult census data set</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">census_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">DATA_DIR</span> <span class="o">+</span> <span class="s2">&quot;adult.csv&quot;</span><span class="p">)</span>
<span class="n">census_df</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">,</span> <span class="n">test_df</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">census_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_nan</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">test_df_nan</span> <span class="o">=</span> <span class="n">test_df</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;?&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">train_df_nan</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s identify numeric and categorical features</span>

<span class="n">numeric_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;age&quot;</span><span class="p">,</span>
    <span class="s2">&quot;capital.gain&quot;</span><span class="p">,</span>
    <span class="s2">&quot;capital.loss&quot;</span><span class="p">,</span>
    <span class="s2">&quot;hours.per.week&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">categorical_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;workclass&quot;</span><span class="p">,</span>
    <span class="s2">&quot;marital.status&quot;</span><span class="p">,</span>
    <span class="s2">&quot;occupation&quot;</span><span class="p">,</span>
    <span class="s2">&quot;relationship&quot;</span><span class="p">,</span>
    <span class="s2">&quot;race&quot;</span><span class="p">,</span>
    <span class="s2">&quot;native.country&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">ordinal_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;education&quot;</span><span class="p">]</span>
<span class="n">binary_features</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;sex&quot;</span>
<span class="p">]</span>  <span class="c1"># Not binary in general but in this particular dataset it seems to have only two possible values</span>
<span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;education.num&quot;</span><span class="p">,</span> <span class="s2">&quot;fnlwgt&quot;</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;income&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;education&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">education_levels</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;Preschool&quot;</span><span class="p">,</span>
    <span class="s2">&quot;1st-4th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;5th-6th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;7th-8th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;9th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;10th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;11th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;12th&quot;</span><span class="p">,</span>
    <span class="s2">&quot;HS-grad&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Prof-school&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Assoc-voc&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Assoc-acdm&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Some-college&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Bachelors&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Masters&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Doctorate&quot;</span><span class="p">,</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="nb">set</span><span class="p">(</span><span class="n">education_levels</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s2">&quot;education&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">())</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">train_df_nan</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">train_df_nan</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>

<span class="n">X_test</span> <span class="o">=</span> <span class="n">test_df_nan</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">test_df_nan</span><span class="p">[</span><span class="n">target</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.compose</span> <span class="kn">import</span> <span class="n">ColumnTransformer</span><span class="p">,</span> <span class="n">make_column_transformer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span><span class="p">,</span> <span class="n">OrdinalEncoder</span><span class="p">,</span> <span class="n">StandardScaler</span>

<span class="n">numeric_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">())</span>

<span class="n">ordinal_transformer</span> <span class="o">=</span> <span class="n">OrdinalEncoder</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">education_levels</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

<span class="n">categorical_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">),</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">sparse_output</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">binary_transformer</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;constant&quot;</span><span class="p">,</span> <span class="n">fill_value</span><span class="o">=</span><span class="s2">&quot;missing&quot;</span><span class="p">),</span>
    <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s2">&quot;if_binary&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">),</span>
<span class="p">)</span>

<span class="n">preprocessor</span> <span class="o">=</span> <span class="n">make_column_transformer</span><span class="p">(</span>
    <span class="p">(</span><span class="n">numeric_transformer</span><span class="p">,</span> <span class="n">numeric_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">ordinal_transformer</span><span class="p">,</span> <span class="n">ordinal_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">binary_transformer</span><span class="p">,</span> <span class="n">binary_features</span><span class="p">),</span>
    <span class="p">(</span><span class="n">categorical_transformer</span><span class="p">,</span> <span class="n">categorical_features</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;drop&quot;</span><span class="p">,</span> <span class="n">drop_features</span><span class="p">),</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_train</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span>
    <span class="n">preprocessor</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">class_weight</span><span class="o">=</span><span class="s2">&quot;balanced&quot;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s examine confusion matrix separately for the two genders we have in the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_enc</span> <span class="o">=</span> <span class="n">preprocessor</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">preprocessor</span><span class="o">.</span><span class="n">named_transformers_</span><span class="p">[</span><span class="s2">&quot;pipeline-2&quot;</span><span class="p">][</span><span class="s2">&quot;onehotencoder&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_female</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;sex==&#39;Female&#39;&quot;</span><span class="p">)</span>  <span class="c1"># X where sex is female</span>
<span class="n">X_male</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;sex==&#39;Male&#39;&quot;</span><span class="p">)</span>  <span class="c1"># X where sex is male</span>

<span class="n">y_female</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">X_female</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>  <span class="c1"># y where sex is female</span>
<span class="n">y_male</span> <span class="o">=</span> <span class="n">y_test</span><span class="p">[</span><span class="n">X_male</span><span class="o">.</span><span class="n">index</span><span class="p">]</span>  <span class="c1"># y where sex is male</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Get predictions for <code class="docutils literal notranslate"><span class="pre">X_female</span></code> and <code class="docutils literal notranslate"><span class="pre">y_male</span></code> with <code class="docutils literal notranslate"><span class="pre">pipe_lr</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">female_preds</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_female</span><span class="p">)</span>
<span class="n">male_preds</span> <span class="o">=</span> <span class="n">pipe_lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_male</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s examine the accuracy and confusion matrix for female and male classes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_female</span><span class="p">,</span> <span class="n">female_preds</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_male</span><span class="p">,</span> <span class="n">male_preds</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot the female confusion matrix</span>
<span class="n">female_cm</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_female</span><span class="p">,</span> <span class="n">y_female</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix - Female&#39;</span><span class="p">);</span>
<span class="n">female_cm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>


<span class="c1"># Plot the male confusion matrix</span>
<span class="n">male_cm</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="o">.</span><span class="n">from_estimator</span><span class="p">(</span><span class="n">pipe_lr</span><span class="p">,</span> <span class="n">X_male</span><span class="p">,</span> <span class="n">y_male</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="s2">&quot;true&quot;</span><span class="p">);</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Confusion Matrix - Male&#39;</span><span class="p">);</span>
<span class="n">male_cm</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<section id="questions-for-group-discussion">
<h3>❓❓ Questions for group discussion<a class="headerlink" href="#questions-for-group-discussion" title="Link to this heading">#</a></h3>
<p>Let’s assume that a company is using this classifier for loan approval with a simple rule that if the income is &gt;=50K, approve the loan else reject the loan.</p>
<p>In your group, discuss the questions below.</p>
<ol class="arabic simple">
<li><p>Which group has a higher accuracy?</p></li>
<li><p>Which group has a higher precision for class &gt;50K? What about recall for class &gt;50K?</p></li>
<li><p>Will both groups have more or less the same proportion of people with approved loans?</p></li>
<li><p>If a male and a female have both a certain level of income, will they have the same chance of getting the loan?</p></li>
<li><p>Banks want to avoid approving unqualified applications (false positives) because default loan could have detrimental effects for them. Compare the false positive rates for the two groups.</p></li>
<li><p>Overall, do you think this income classifier will fairly treat both groups? What will be the consequences of using this classifier in loan approval application?</p></li>
</ol>
<p><strong>Time permitting</strong></p>
<ol class="arabic simple">
<li><p>Do you think the effect will still exist if the sex feature is removed from the model (but you still have it available separately to do the two confusion matrices)?</p></li>
<li><p>Are there any other groups in this dataset worth examining for biases?</p></li>
</ol>
<p><br><br></p>
</section>
</section>
<section id="what-did-we-learn-today">
<h2>What did we learn today?<a class="headerlink" href="#what-did-we-learn-today" title="Link to this heading">#</a></h2>
<ul class="simple">
<li><p>A number of possible ways to evaluate machine learning models</p>
<ul>
<li><p>Choose the evaluation metric that makes most sense in your context or which is most common in your discipline</p></li>
</ul>
</li>
<li><p>Two kinds of binary classification problems</p>
<ul>
<li><p>Distinguishing between two classes (e.g., dogs vs. cats)</p></li>
<li><p>Spotting a class (e.g., spot fraud transaction, spot spam)</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Precision, recall, f1-score are useful when dealing with spotting problems.</p></li>
<li><p>The thing that we are interested in spotting is considered “positive”.</p></li>
<li><p>Do you need to deal with class imbalance in the given problem?</p></li>
<li><p>Methods to deal with class imbalance</p>
<ul>
<li><p>Changing the training procedure</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">class_weight</span></code></p></li>
</ul>
</li>
<li><p>Changing the data</p>
<ul>
<li><p>undersampling, oversampling, SMOTE</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Do not blindly make decisions solely based on ML model predictions.</p></li>
<li><p>Try to carefully analyze the errors made by the model on certain groups.</p></li>
</ul>
<section id="relevant-papers-and-resources">
<h3>Relevant papers and resources<a class="headerlink" href="#relevant-papers-and-resources" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><a class="reference external" href="https://www.biostat.wisc.edu/~page/rocpr.pdf">The Relationship Between Precision-Recall and ROC Curves</a></p></li>
<li><p><a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432">Article claiming that PR curve are better than ROC for imbalanced datasets</a></p></li>
<li><p><a class="reference external" href="https://papers.nips.cc/paper/2015/file/33e8075e9970de0cfea955afd4644bb2-Paper.pdf">Precision-Recall-Gain Curves: PR Analysis Done Right</a></p></li>
<li><p><a class="reference external" href="https://github.com/dariyasydykova/open_projects/tree/master/ROC_animation">ROC animation</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/pdf/1506.02629.pdf">Generalization in Adaptive Data Analysis and Holdout Reuse</a></p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "conda-env-cpsc330-py"
        },
        kernelOptions: {
            name: "conda-env-cpsc330-py",
            path: "./lectures/102-Varada-lectures/class_demos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'conda-env-cpsc330-py'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#imports">Imports</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#machine-learning-workflow">Machine learning workflow</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-metrics-for-binary-classification-motivation">Evaluation metrics for binary classification: Motivation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-for-demonstration">Dataset for demonstration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#eda">EDA</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#baseline">Baseline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#observations">Observations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#thresholding">Thresholding</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix">Confusion matrix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-types-of-errors-would-be-most-critical-for-the-bank-to-address">Which types of errors would be most critical for the bank to address?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-positive-and-negative">What is “positive” and “negative”?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#confusion-matrix-with-cross-validation">Confusion matrix with cross-validation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-f1-score">Precision, recall, f1 score</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-and-recall-toy-example">Precision and recall: toy example</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision">Precision</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recall">Recall</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#f1-score">F1-score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-report">Classification report</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interim-summary">Interim summary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evalution-metrics-overview">Evalution metrics overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation-with-different-metrics">Cross validation with different metrics</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-curve">Precision-recall curve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#operating-point">Operating point</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#precision-recall-tradeoff">Precision/Recall tradeoff</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decreasing-the-threshold">Decreasing the threshold</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#increasing-the-threshold">Increasing the threshold</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Precision-recall curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ap-score">AP score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ap-vs-f1-score">AP vs. F1-score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-few-comments-on-pr-curve">A few comments on PR curve</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-some-more-details">(Optional) Some more details</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pr-curves-for-logistic-regression-and-svc">PR curves for logistic regression and SVC</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#which-model-is-doing-better-in-this-scenario-svc-or-logistic-regression">Which model is doing better in this scenario: SVC or Logistic Regression?</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#receiver-operating-characteristic-roc-curve">Receiver Operating Characteristic (ROC) curve</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#area-under-the-curve-auc">Area under the curve (AUC)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#let-s-look-at-all-the-scores-at-once">Let’s look at all the scores at once</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dealing-with-class-imbalance-video">Dealing with class imbalance [video]</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-imbalance-in-training-sets">Class imbalance in training sets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#addressing-class-imbalance">Addressing class imbalance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#which-type-of-error-is-more-important">Which type of error is more important?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-imbalance">Handling imbalance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#changing-the-training-procedure">Changing the training procedure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#example-class-weight-parameter-of-sklearn-logisticregression">Example: <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">sklearn</span> <span class="pre">LogisticRegression</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#class-weight-balanced"><code class="docutils literal notranslate"><span class="pre">class_weight="balanced"</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#are-we-doing-better-with-class-weight-balanced">Are we doing better with <code class="docutils literal notranslate"><span class="pre">class_weight="balanced"</span></code>?</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stratified-splits">Stratified Splits</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#is-stratifying-a-good-idea">Is stratifying a good idea?</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-changing-the-data">(Optional) Changing the data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#undersampling">Undersampling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#oversampling">Oversampling</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smote-synthetic-minority-over-sampling-technique">SMOTE: Synthetic Minority Over-sampling Technique</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#smote-idea">SMOTE idea</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-smote">Using SMOTE</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ml-fairness-activity-5-mins">ML fairness activity (~5 mins)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#questions-for-group-discussion">❓❓ Questions for group discussion</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-did-we-learn-today">What did we learn today?</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relevant-papers-and-resources">Relevant papers and resources</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varada Kolhatkar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>